"""Schemas definitions using Pydantic BaseModel for the SynThesisAI application."""

# Standard Library
from datetime import datetime
from decimal import Decimal
from typing import Any, Dict, Generator, List, Optional

# Third-Party Library
from pydantic import BaseModel


class ModelConfig(BaseModel):
    """Model configuration specifying provider and model name.

    Attributes:
        provider (str): The model provider, e.g., "openai", "gemini".
        model_name (str): The specific model identifier.
    """

    provider: str
    model_name: str


class Prompt(BaseModel):
    """Representation of a prompt with subject, topic, problem, and hints.

    Attributes:
        subject (str): The subject of the prompt.
        topic (str): The topic within the subject.
        problem (str): The problem statement.
        answer (str): The correct answer to the problem.
        hints (Dict[str, str]): Mapping of hint identifiers to hint content.
        reference (Optional[str]): Optional reference source or ID.
        hints_were_corrected (Optional[bool]): Whether hints were corrected.
        target_model_answer (Optional[Any]): Answer as generated by target model.
    """

    subject: str
    topic: str
    problem: str
    answer: str
    hints: Dict[str, str]
    reference: Optional[str] = None
    hints_were_corrected: Optional[bool] = False
    target_model_answer: Optional[Any] = None


class GenerationResponse(BaseModel):
    """Response containing valid and discarded prompts and metadata.

    Attributes:
        valid_prompts (List[Prompt]): List of successfully generated prompts.
        discarded_prompts (List[Any]): List of prompts discarded during generation.
        metadata (Dict[str, Any]): Additional metadata about generation.
    """

    valid_prompts: List[Prompt]
    discarded_prompts: List[Any]
    metadata: Dict[str, Any]


class GenerationStatus(BaseModel):
    """Status of an ongoing generation batch.

    Attributes:
        batch_id (int): Unique identifier for the batch.
        total_needed (int): Total required prompts.
        valid_generated (int): Count of valid prompts generated.
        total_generated (int): Count of all prompts generated.
        progress_percentage (float): Completion percentage of the batch.
        stats (Dict[str, int]): Statistics about prompt categories.
        batch_cost (float): Cost incurred for this batch.
        status (str): Current status string (e.g., "running", "completed").
    """

    batch_id: int
    total_needed: int
    valid_generated: int
    total_generated: int
    progress_percentage: float
    stats: Dict[str, int]
    batch_cost: float
    status: str


class BatchBase(BaseModel):
    """Base schema for batch operations.

    Attributes:
        name (str): Name of the batch.
        taxonomy_json (Dict[str, Any]): Taxonomy configuration.
        pipeline (Dict[str, Any]): Pipeline component settings.
        num_problems (int): Number of problems to generate.
    """

    name: str
    taxonomy_json: Dict[str, Any]
    pipeline: Dict[str, Any]
    num_problems: int


class BatchCreate(BatchBase):
    """Schema for creating a new batch.

    Attributes:
        batch_cost (Optional[Decimal]): Estimated cost for the batch.
    """

    batch_cost: Optional[Decimal] = Decimal("0.00")


class Batch(BatchBase):
    """Schema representing a batch with persistent metadata.

    Attributes:
        id (int): Unique batch identifier.
        batch_cost (Decimal): Final cost for the batch.
        created_at (datetime): Creation timestamp.
        updated_at (Optional[datetime]): Last update timestamp.
    """

    id: int
    batch_cost: Decimal
    created_at: datetime
    updated_at: Optional[datetime]

    class Config:
        from_attributes = True


class BatchWithStats(Batch):
    """Batch schema including detailed statistics.

    Attributes:
        stats (Dict[str, int]): Detailed metrics for batch results.
    """

    stats: Dict[str, int]


class ProblemBase(BaseModel):
    """Base schema for problem entities.

    Attributes:
        subject (str): Subject domain of the problem.
        topic (str): Topic within the subject.
        question (str): Problem question text.
        answer (str): Provided answer text.
        hints (Dict[str, Any]): Supplemental hints data.
        status (str): Current status of the problem.
        reference (Optional[str]): Optional source reference.
    """

    subject: str
    topic: str
    question: str
    answer: str
    hints: Dict[str, Any]
    status: str
    reference: Optional[str] = None


class ProblemCreate(ProblemBase):
    """Schema for creating a new problem record.

    Attributes:
        batch_id (int): Identifier of associated batch.
        rejection_reason (Optional[str]): Reason for rejection if any.
        problem_embedding (Optional[Dict[str, Any]]): Embedding data.
        similar_problems (Dict[str, Any]): Related problem mappings.
        cost (Decimal): Estimated cost for problem generation.
        target_model_answer (Optional[str]): Answer from target model.
        hints_were_corrected (bool): Flag if hints were corrected.
    """

    batch_id: int
    rejection_reason: Optional[str] = None
    problem_embedding: Optional[Dict[str, Any]] = None
    similar_problems: Dict[str, Any] = {}
    cost: Decimal = Decimal("0.00")
    target_model_answer: Optional[str] = None
    hints_were_corrected: bool = False


class Problem(ProblemBase):
    """Schema representing a persisted problem record.

    Attributes:
        id (int): Unique problem identifier.
        batch_id (int): Identifier of associated batch.
        rejection_reason (Optional[str]): Reason for rejection if any.
        created_at (datetime): Record creation timestamp.
        updated_at (Optional[datetime]): Last update timestamp.
        problem_embedding (Optional[Dict[str, Any]]): Embedding data.
        similar_problems (Dict[str, Any]): Related problem mappings.
        cost (Decimal): Final cost for generation.
        target_model_answer (Optional[str]): Answer from target model.
        hints_were_corrected (bool): Flag if hints were corrected.
        reference (Optional[str]): Optional source reference.
    """

    id: int
    batch_id: int
    rejection_reason: Optional[str]
    created_at: datetime
    updated_at: Optional[datetime]
    problem_embedding: Optional[Dict[str, Any]]
    similar_problems: Dict[str, Any]
    cost: Decimal
    target_model_answer: Optional[str]
    hints_were_corrected: bool
    reference: Optional[str]

    class Config:
        from_attributes = True


class ProblemResponse(ProblemBase):
    """Response schema for problem entities.

    Attributes:
        id (int): Unique problem identifier.
        batch_id (int): Identifier of associated batch.
        rejection_reason (Optional[str]): Reason for rejection.
        created_at (datetime): Record creation timestamp.
        updated_at (Optional[datetime]): Last update timestamp.
        similar_problems (Dict[str, Any]): Related problem mappings.
        cost (Decimal): Final cost for generation.
        target_model_answer (Optional[str]): Answer from target model.
        hints_were_corrected (bool): Flag if hints were corrected.
        reference (Optional[str]): Optional source reference.
    """

    id: int
    batch_id: int
    rejection_reason: Optional[str]
    created_at: datetime
    updated_at: Optional[datetime]
    similar_problems: Dict[str, Any]
    cost: Decimal
    target_model_answer: Optional[str]
    hints_were_corrected: bool
    reference: Optional[str]

    class Config:
        from_attributes = True


class GenerationRequest(BaseModel):
    """Request schema for generation of problems.

    Attributes:
        num_problems (int): Number of problems to generate.
        engineer_model (ModelConfig): Configuration for engineer model.
        checker_model (ModelConfig): Configuration for checker model.
        target_model (ModelConfig): Configuration for target model.
        taxonomy (Optional[Dict[str, Any]]): Taxonomy data if not using seed.
        use_seed_data (Optional[bool]): Flag to use seed data.
        benchmark_name (Optional[str]): Name of benchmark dataset.
        seed_data (Optional[List[Dict[str, Any]]]): Seed data list.
        use_search (bool): Whether to enable search augmentation.
    """

    num_problems: int
    engineer_model: ModelConfig
    checker_model: ModelConfig
    target_model: ModelConfig
    taxonomy: Optional[Dict[str, Any]] = None
    use_seed_data: Optional[bool] = False
    benchmark_name: Optional[str] = None
    seed_data: Optional[List[Dict[str, Any]]] = None
    use_search: bool = True

    @classmethod
    def validate_request(cls, values: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validates the generation request.

        Args:
            values (Dict[str, Any]): Field values for validation.

        Raises:
            ValueError: If required fields are missing based on flags.

        Returns:
            Dict[str, Any]: Validated values.
        """
        use_seed = values.get("use_seed_data", False)
        taxonomy = values.get("taxonomy")
        benchmark = values.get("benchmark_name")
        seed_data = values.get("seed_data")

        if not use_seed and not taxonomy:
            raise ValueError("Must provide either taxonomy or seed_data.")

        if use_seed and not (benchmark or seed_data):
            raise ValueError(
                "Must provide either benchmark_name or seed_data when " "use_seed_data is True."
            )

        return values

    @classmethod
    def __get_validators__(cls) -> Generator:
        """
        Yields validators for Pydantic initialization.

        Returns:
            Generator: Validator generator.
        """
        yield cls.validate_request


class PipelineConfig(BaseModel):
    """Configuration for pipeline components.

    Attributes:
        generator (Dict[str, str]): Mapping for generator settings.
        hinter (Dict[str, str]): Mapping for hinter settings.
        checker (Dict[str, str]): Mapping for checker settings.
        target (Dict[str, str]): Mapping for target settings.
        judge (Dict[str, str]): Mapping for judge settings.
    """

    generator: Dict[str, str]
    hinter: Dict[str, str]
    checker: Dict[str, str]
    target: Dict[str, str]
    judge: Dict[str, str]


class TargetModelUpdate(BaseModel):
    """Schema for updating the target model configuration.

    Attributes:
        target_model (ModelConfig): New target model configuration.
    """

    target_model: ModelConfig

#!/usr/bin/env python3
"""
Script to run all Phase 2 MARL coordination tests.

This script runs all unit tests and integration tests for Phase 2 of the MARL coordination system.
"""

import logging
import subprocess
import sys
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)


def run_tests():
    """Run all Phase 2 tests."""
    logger.info("üöÄ Running Phase 2 MARL coordination tests...")

    # Define test categories and their corresponding test files
    test_categories = {
        "MARL Agents": [
            "tests/unit_tests/test_base_agent.py",
            "tests/unit_tests/test_generator_agent.py",
            "tests/unit_tests/test_validator_agent.py",
            "tests/unit_tests/test_curriculum_agent.py",
        ],
        "Coordination Mechanisms": [
            "tests/unit_tests/test_coordination_policy.py",
            "tests/unit_tests/test_consensus_manager.py",
            "tests/unit_tests/test_communication_protocol.py",
        ],
        "Shared Learning": [
            "tests/unit_tests/test_shared_experience.py",
            "tests/unit_tests/test_continuous_learning.py",
        ],
        "Performance Monitoring": [
            "tests/unit_tests/test_performance_monitor.py",
            "tests/unit_tests/test_performance_analyzer.py",
            "tests/unit_tests/test_performance_reporter.py",
        ],
        "Configuration Management": [
            "tests/unit_tests/test_config_manager.py",
            "tests/unit_tests/test_config_validator.py",
        ],
        "Experimentation Framework": [
            "tests/unit_tests/test_experiment_manager.py",
            "tests/unit_tests/test_ab_testing.py",
        ],
        "Error Handling": [
            "tests/unit_tests/test_error_handling.py",
        ],
        "Fault Tolerance": [
            "tests/unit_tests/test_fault_tolerance.py",
        ],
    }

    # Track overall results
    all_results = {}
    overall_success = True

    # Run tests by category
    for category, test_files in test_categories.items():
        logger.info(f"\nüìã Running {category} tests...")

        # Filter existing test files
        existing_files = []
        for test_file in test_files:
            if Path(test_file).exists():
                existing_files.append(test_file)
            else:
                logger.warning(f"‚ö†Ô∏è  Test file not found: {test_file}")

        if not existing_files:
            logger.warning(f"‚ö†Ô∏è  No test files found for {category}")
            continue

        # Run tests for this category
        result = subprocess.run(
            ["uv", "run", "python", "-m", "pytest"]
            + existing_files
            + ["-v", "--tb=short"],
            capture_output=True,
            text=True,
            check=False,
        )

        all_results[category] = result

        # Print results
        if result.returncode == 0:
            logger.info(f"‚úÖ {category} tests PASSED")
        else:
            logger.error(f"‚ùå {category} tests FAILED")
            overall_success = False

        # Print test output (abbreviated)
        if result.stdout:
            lines = result.stdout.split("\n")
            # Show summary line
            for line in lines:
                if "passed" in line and "failed" in line:
                    logger.info(f"   {line.strip()}")
                    break
                elif "passed" in line and line.strip().endswith("passed"):
                    logger.info(f"   {line.strip()}")
                    break

        if result.stderr and result.returncode != 0:
            logger.error(f"   Error output: {result.stderr[:200]}...")

    # Run end-to-end tests
    logger.info("\nüìã Running End-to-End tests...")
    e2e_result = subprocess.run(
        [
            "uv",
            "run",
            "python",
            "-m",
            "pytest",
            "tests/end_to_end/test_phase2_comprehensive.py",
            "-v",
            "--tb=short",
        ],
        capture_output=True,
        text=True,
        check=False,
    )

    all_results["End-to-End"] = e2e_result

    if e2e_result.returncode == 0:
        logger.info("‚úÖ End-to-End tests PASSED")
    else:
        logger.error("‚ùå End-to-End tests FAILED")
        overall_success = False
        if e2e_result.stderr:
            logger.error(f"   Error output: {e2e_result.stderr[:200]}...")

    # Print comprehensive summary
    logger.info("\n" + "=" * 60)
    logger.info("üìä PHASE 2 TEST SUMMARY")
    logger.info("=" * 60)

    total_categories = len(all_results)
    passed_categories = sum(
        1 for result in all_results.values() if result.returncode == 0
    )

    for category, result in all_results.items():
        status = "‚úÖ PASSED" if result.returncode == 0 else "‚ùå FAILED"
        logger.info(f"{category:.<30} {status}")

    logger.info("-" * 60)
    logger.info(f"Categories passed: {passed_categories}/{total_categories}")

    if overall_success:
        logger.info("üéâ ALL PHASE 2 TESTS PASSED! MARL coordination system is ready!")
        logger.info("‚ú® Key achievements:")
        logger.info("   ‚Ä¢ Multi-agent RL coordination implemented")
        logger.info("   ‚Ä¢ Consensus mechanisms working")
        logger.info("   ‚Ä¢ Shared learning infrastructure operational")
        logger.info("   ‚Ä¢ Performance monitoring active")
        logger.info("   ‚Ä¢ Configuration management ready")
        logger.info("   ‚Ä¢ Experimentation framework functional")
        logger.info("   ‚Ä¢ Error handling and fault tolerance robust")
        return 0
    else:
        failed_categories = total_categories - passed_categories
        logger.error(
            f"‚ö†Ô∏è  {failed_categories} test categories failed. Please review and fix."
        )
        logger.error("üîß Common issues to check:")
        logger.error("   ‚Ä¢ Missing dependencies or imports")
        logger.error("   ‚Ä¢ Configuration file issues")
        logger.error("   ‚Ä¢ Async/await syntax problems")
        logger.error("   ‚Ä¢ Mock object setup")
        return 1


def print_detailed_results():
    """Print detailed test results for debugging."""
    logger.info("\nüîç For detailed test output, run individual test categories:")
    logger.info("   uv run pytest tests/unit_tests/test_error_handling.py -v")
    logger.info("   uv run pytest tests/unit_tests/test_fault_tolerance.py -v")
    logger.info("   uv run pytest tests/unit_tests/test_experiment_manager.py -v")
    logger.info("   uv run pytest tests/end_to_end/test_phase2_comprehensive.py -v")


if __name__ == "__main__":
    exit_code = run_tests()
    if exit_code != 0:
        print_detailed_results()
    sys.exit(exit_code)
